{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configuration\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "import dataset_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create data loader object\n",
    "## image transformation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as T\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "\n",
    "\n",
    "from configuration import *\n",
    "from  dataset_dataloader import *\n",
    "from cross_modal_cvae_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir='/home/ubuntu/project2/StarGAN/data/celeba/images'\n",
    "attr_path='/home/ubuntu/project2/StarGAN/data/celeba/list_attr_celeba.txt'\n",
    "selected_attrs=['Male' ,'Young']\n",
    "target_dir_MY = '/home/ubuntu/project2/CELEBA_DATA/MY'\n",
    "target_dir_FY = '/home/ubuntu/project2/CELEBA_DATA/FY'\n",
    "target_dir_MO = '/home/ubuntu/project2/CELEBA_DATA/MO'\n",
    "target_dir_FO = '/home/ubuntu/project2/CELEBA_DATA/FO'\n",
    "mode = 'train'\n",
    "batch_size = 5\n",
    "num_workers=1\n",
    "crop_size=178\n",
    "image_size=64\n",
    "\n",
    "transform = []\n",
    "if mode == 'train':\n",
    "    transform.append(T.RandomHorizontalFlip())\n",
    "transform.append(T.CenterCrop(crop_size))\n",
    "transform.append(T.Resize(image_size))\n",
    "transform.append(T.ToTensor())\n",
    "#transform.append(T.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)))\n",
    "transform = T.Compose(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished preprocessing the CelebA dataset...\n"
     ]
    }
   ],
   "source": [
    "dataset = CelebA(image_dir, attr_path, selected_attrs, transform, mode)\n",
    "data_loader = data.DataLoader(dataset=dataset,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=(mode=='train'),\n",
    "                                  num_workers=num_workers)\n",
    "data_iter = iter(data_loader)\n",
    "start_iters = 0\n",
    "num_iters = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.distributions.normal.Normal(torch.tensor([0.0]), torch.tensor([1.0]))\n",
    "b=a.sample((1,8,1,1))\n",
    "xx=b.squeeze(4).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM_gen = CrossModal(lambda_p, lambda_s, xx)\n",
    "CM_gen = CM_gen.to(DEVICE)\n",
    "CM_gen_optimizer = torch.optim.Adam(CM_gen.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossModal(\n",
       "  (Utterance_Encoder): UtteranceEncoder(\n",
       "    (conv1): Conv2d(1, 8, kernel_size=(3, 9), stride=(1, 1), padding=(1, 4))\n",
       "    (conv1_bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv1_gated): Conv2d(1, 8, kernel_size=(3, 9), stride=(1, 1), padding=(1, 4))\n",
       "    (conv1_gated_bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv1_sigmoid): Sigmoid()\n",
       "    (conv2): Conv2d(8, 16, kernel_size=(4, 8), stride=(2, 2), padding=(1, 3))\n",
       "    (conv2_bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2_gated): Conv2d(8, 16, kernel_size=(4, 8), stride=(2, 2), padding=(1, 3))\n",
       "    (conv2_gated_bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2_sigmoid): Sigmoid()\n",
       "    (conv3): Conv2d(16, 16, kernel_size=(4, 8), stride=(2, 2), padding=(1, 3))\n",
       "    (conv3_bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3_gated): Conv2d(16, 16, kernel_size=(4, 8), stride=(2, 2), padding=(1, 3))\n",
       "    (conv3_gated_bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3_sigmoid): Sigmoid()\n",
       "    (conv4_mu): Conv2d(16, 8, kernel_size=(9, 5), stride=(9, 1), padding=(1, 2))\n",
       "    (conv4_logvar): Conv2d(16, 8, kernel_size=(9, 5), stride=(9, 1), padding=(1, 2))\n",
       "  )\n",
       "  (Utterance_Decoder): UtteranceDecoder(\n",
       "    (upconv1): ConvTranspose2d(16, 16, kernel_size=(9, 5), stride=(9, 1), padding=(0, 2))\n",
       "    (upconv1_bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (upconv1_gated): ConvTranspose2d(16, 16, kernel_size=(9, 5), stride=(9, 1), padding=(0, 2))\n",
       "    (upconv1_gated_bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (upconv1_sigmoid): Sigmoid()\n",
       "    (upconv2): ConvTranspose2d(24, 16, kernel_size=(4, 8), stride=(2, 2), padding=(1, 3))\n",
       "    (upconv2_bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (upconv2_gated): ConvTranspose2d(24, 16, kernel_size=(4, 8), stride=(2, 2), padding=(1, 3))\n",
       "    (upconv2_gated_bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (upconv2_sigmoid): Sigmoid()\n",
       "    (upconv3): ConvTranspose2d(24, 8, kernel_size=(4, 8), stride=(2, 2), padding=(1, 3))\n",
       "    (upconv3_bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (upconv3_gated): ConvTranspose2d(24, 8, kernel_size=(4, 8), stride=(2, 2), padding=(1, 3))\n",
       "    (upconv3_gated_bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (upconv3_sigmoid): Sigmoid()\n",
       "    (upconv4_mu): ConvTranspose2d(16, 1, kernel_size=(3, 9), stride=(1, 1), padding=(1, 4))\n",
       "    (upconv4_logvar): ConvTranspose2d(16, 1, kernel_size=(3, 9), stride=(1, 1), padding=(1, 4))\n",
       "    (bcast_linear1): Linear(in_features=1, out_features=256, bias=True)\n",
       "    (bcast_linear2): Linear(in_features=1, out_features=9, bias=True)\n",
       "    (bcast_linear3): Linear(in_features=9, out_features=18, bias=True)\n",
       "    (bcast_linear4): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (bcast_linear5): Linear(in_features=18, out_features=36, bias=True)\n",
       "    (bcast_linear6): Linear(in_features=512, out_features=1024, bias=True)\n",
       "  )\n",
       "  (Face_Encoder): FaceEncoder(\n",
       "    (FaceEncoder_Layers): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), bias=False)\n",
       "      (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (2): ConvBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(6, 6), stride=(2, 2), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LRelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      )\n",
       "      (3): ConvBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LRelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      )\n",
       "      (4): ConvBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LRelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      )\n",
       "      (5): ConvBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LRelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      )\n",
       "      (6): ConvBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (LRelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (FaceEncoder_Layers2): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (2): Linear(in_features=256, out_features=16, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "    (mu_layer): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (var_layer): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (Face_Decoder): FaceDecoder(\n",
       "    (lin): Linear(in_features=1, out_features=128, bias=True)\n",
       "    (FaceDecoder_Layers): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=128, bias=True)\n",
       "      (1): Softplus(beta=1, threshold=20)\n",
       "      (2): Linear(in_features=128, out_features=2048, bias=True)\n",
       "      (3): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (FaceDecoder_Layers1): Sequential(\n",
       "      (0): Linear(in_features=136, out_features=1, bias=True)\n",
       "      (1): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (FaceDecoder_Layers21): DeConvBlock(\n",
       "      (deconv1): ConvTranspose2d(192, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (FaceDecoder_Layers22): DeConvBlock(\n",
       "      (deconv1): ConvTranspose2d(136, 128, kernel_size=(6, 6), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (FaceDecoder_Layers23): DeConvBlock(\n",
       "      (deconv1): ConvTranspose2d(128, 64, kernel_size=(6, 6), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (FaceDecoder_Layers24): DeConvBlock(\n",
       "      (deconv1): ConvTranspose2d(72, 32, kernel_size=(6, 6), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (FaceDecoder_Layers25): DeConvBlock(\n",
       "      (deconv1): ConvTranspose2d(32, 16, kernel_size=(6, 6), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (FaceDecoder_Layers26): Conv2d(24, 6, kernel_size=(6, 6), stride=(1, 1))\n",
       "    (mu_conv): Conv2d(6, 3, kernel_size=(8, 8), stride=(3, 3))\n",
       "    (var_conv): Conv2d(6, 3, kernel_size=(8, 8), stride=(3, 3))\n",
       "    (lin1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "    (lin2): Linear(in_features=128, out_features=81, bias=True)\n",
       "    (lin3): Linear(in_features=128, out_features=2304, bias=True)\n",
       "    (lin4): Linear(in_features=48, out_features=204, bias=True)\n",
       "    (lin5): Linear(in_features=48, out_features=204, bias=True)\n",
       "  )\n",
       "  (Voice_Encoder): VoiceEncoder(\n",
       "    (conv1): Conv2d(1, 32, kernel_size=(3, 9), stride=(1, 1), padding=(1, 4))\n",
       "    (conv1_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv1_gated): Conv2d(1, 32, kernel_size=(3, 9), stride=(1, 1), padding=(1, 4))\n",
       "    (conv1_gated_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv1_sigmoid): Sigmoid()\n",
       "    (conv2): Conv2d(32, 64, kernel_size=(4, 8), stride=(2, 2), padding=(1, 3))\n",
       "    (conv2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2_gated): Conv2d(32, 64, kernel_size=(4, 8), stride=(2, 2), padding=(1, 3))\n",
       "    (conv2_gated_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2_sigmoid): Sigmoid()\n",
       "    (conv3): Conv2d(64, 128, kernel_size=(4, 8), stride=(2, 2), padding=(1, 3))\n",
       "    (conv3_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3_gated): Conv2d(64, 128, kernel_size=(4, 8), stride=(2, 2), padding=(1, 3))\n",
       "    (conv3_gated_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3_sigmoid): Sigmoid()\n",
       "    (conv4): Conv2d(128, 128, kernel_size=(4, 8), stride=(2, 2), padding=(1, 3))\n",
       "    (conv4_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv4_gated): Conv2d(128, 128, kernel_size=(4, 8), stride=(2, 2), padding=(1, 3))\n",
       "    (conv4_gated_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv4_sigmoid): Sigmoid()\n",
       "    (conv5): Conv2d(128, 128, kernel_size=(4, 5), stride=(4, 1), padding=(1, 5))\n",
       "    (conv5_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv5_gated): Conv2d(128, 128, kernel_size=(4, 5), stride=(4, 1), padding=(1, 5))\n",
       "    (conv5_gated_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv5_sigmoid): Sigmoid()\n",
       "    (conv6): Conv2d(128, 64, kernel_size=(1, 5), stride=(1, 1), padding=(1, 5))\n",
       "    (conv6_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv6_gated): Conv2d(128, 64, kernel_size=(1, 5), stride=(1, 1), padding=(1, 5))\n",
       "    (conv6_gated_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv6_sigmoid): Sigmoid()\n",
       "    (conv7): Conv2d(64, 16, kernel_size=(1, 5), stride=(1, 1), padding=(1, 5))\n",
       "    (conv7_bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv7_gated): Conv2d(64, 16, kernel_size=(1, 5), stride=(1, 1), padding=(1, 5))\n",
       "    (conv7_gated_bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv7_sigmoid): Sigmoid()\n",
       "    (conv8): Conv2d(16, 8, kernel_size=(1, 5), stride=(1, 1), padding=(1, 5))\n",
       "    (lin1_mu): Linear(in_features=7, out_features=1, bias=True)\n",
       "    (lin2_mu): Linear(in_features=152, out_features=128, bias=True)\n",
       "    (lin1_var): Linear(in_features=7, out_features=1, bias=True)\n",
       "    (lin2_var): Linear(in_features=152, out_features=128, bias=True)\n",
       "  )\n",
       "  (Face_Classifier): Face_Discriminator(\n",
       "    (main): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): Conv2d(1024, 2048, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (11): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (conv1): Conv2d(2048, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(2048, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (Voice_Classifier): Voice_Discriminator(\n",
       "    (ac_conv1): Conv2d(1, 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (ac_conv1_bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ac_conv1_gated): Conv2d(1, 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (ac_conv1_gated_bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ac_conv1_sigmoid): Sigmoid()\n",
       "    (ac_conv2): Conv2d(8, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (ac_conv2_bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ac_conv2_gated): Conv2d(8, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (ac_conv2_gated_bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ac_conv2_sigmoid): Sigmoid()\n",
       "    (ac_conv3): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (ac_conv3_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ac_conv3_gated): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (ac_conv3_gated_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ac_conv3_sigmoid): Sigmoid()\n",
       "    (ac_conv4): Conv2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (ac_conv4_bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ac_conv4_gated): Conv2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (ac_conv4_gated_bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ac_conv4_sigmoid): Sigmoid()\n",
       "    (ac_conv5): Conv2d(16, 4, kernel_size=(1, 4), stride=(1, 2), padding=(0, 1))\n",
       "    (ac_lin1): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (ac_conv6): Conv2d(16, 1, kernel_size=(1, 4), stride=(1, 2), padding=(0, 1))\n",
       "    (ac_lin2): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       "  (L2_loss1): MSELoss()\n",
       "  (L2_loss2): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Conv2d or type(m) == nn.Linear or type(m) == nn.ConvTranspose2d:\n",
    "        torch.nn.init.xavier_normal_(m.weight.data)\n",
    "        \n",
    "CM_gen.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label2onehot(labels, dim):\n",
    "       \"\"\"Convert label indices to one-hot vectors.\"\"\"\n",
    "       batch_size = labels.size(0)\n",
    "       out = torch.zeros(batch_size, dim)\n",
    "       out[np.arange(batch_size), labels.long()] = 1\n",
    "       return out.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=6\n",
    "\n",
    "for epoch in range(0, num_epochs):\n",
    "    epoch += 1\n",
    "    \n",
    "    if (epoch == 7):\n",
    "        learning_rate = learning_rate_ \n",
    "        for param_group in CM_gen_optimizer.param_groups:\n",
    "            param_group['lr'] = learning_rate\n",
    "    if (epoch == 15):\n",
    "        learning_rate = learning_rate__\n",
    "        for param_group in CM_gen_optimizer.param_groups:\n",
    "            param_group['lr'] = learning_rate\n",
    "    if (epoch == 21):\n",
    "        learning_rate = learning_rate___\n",
    "        for param_group in CM_gen_optimizer.param_groups:\n",
    "            param_group['lr'] = learning_rate\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    print('Epoch: %d' % epoch)\n",
    "    \n",
    "    avg_loss = 0\n",
    "    \n",
    "    data_len = len(data_iter)\n",
    "    \n",
    "    data_iter = iter(data_loader)\n",
    "\n",
    "    for (x_face, label_face) in data_iter:\n",
    "       \n",
    "        x_voice, label_voice = data_load_new(batchsize = 20,s = label_face)\n",
    "        \n",
    "        x_face = x_face.to(DEVICE)\n",
    "        label_face = label_face.to(DEVICE)\n",
    "        x_voice = x_voice.to(DEVICE)\n",
    "        label_voice = label_voice.to(DEVICE)\n",
    "        \n",
    "        label_real = label2onehot(labels=label_voice, dim=4)\n",
    "        \n",
    "        \n",
    "        CM_gen_optimizer.zero_grad()\n",
    "        \n",
    "        loss = CM_gen.calculate_loss(x_voice, x_face, label_real)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        CM_gen_optimizer.step()\n",
    "        \n",
    "        avg_loss = avg_loss + loss\n",
    "        \n",
    "        \n",
    "    CAVE_LOSS = avg_loss/data_len\n",
    "    print(\"avg_loss\", CAVE_LOSS)\n",
    "      \n",
    "\n",
    "    if epoch%5 == 0:\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict':CM_gen.state_dict(),\n",
    "                    'optimizer_state_dict': CM_gen_optimizer.state_dict(),\n",
    "                    'loss': CAVE_LOSS,\n",
    "                    }, \"model_params_ACVAE\" + str(epoch) + \".tar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
