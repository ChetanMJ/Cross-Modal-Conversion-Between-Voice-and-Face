# Cross-Modal-Conversion-Between-Voice-and-Face

As humans we can infer a person’s looks from the way they speak, there
is a reason to believe that there exists a co-relation between a person’s
voice and face. This project tries to capture this co-relation and has
the following two goals: Reconstructing a facial image that matches the
audio and generating a voice given a small audio recording and a facial
image. To capture this correlation, our model consists of an utterance
encoder/decoder ,voice encoder, image encoder/decoder and classifiers for
voice and face.
